{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3d29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601967c9",
   "metadata": {},
   "source": [
    "### 1. Load both the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1010fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Urdu Fake News dataset\n",
    "def read_UFN_dataset(files):\n",
    "    text=[]\n",
    "    for i,file_path in enumerate(files):\n",
    "        with open(file_path,'r',encoding='utf8') as infile:\n",
    "            cleantext= infile.read() # can do any preprocessing here!\n",
    "            text.append(cleantext)\n",
    "    return text\n",
    "\n",
    "# call the function to load the real and fake news\n",
    "UFN_real_news = read_UFN_dataset(sorted(Path('UFN/0').glob('*.txt')))\n",
    "UFN_fake_news = read_UFN_dataset(sorted(Path('UFN/1').glob('*.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d0cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Bend the Truth (BET) dataset\n",
    "def preprocessText(text):\n",
    "    #here remove text\n",
    "    cleantext=re.sub(\"\\d+\", \"0\", text)\n",
    "    return cleantext\n",
    "\n",
    "def read_txt_files(files):\n",
    "    text=[]\n",
    "    topic=[]\n",
    "    for i,file_path in enumerate(files):\n",
    "        with open(file_path, 'r', encoding=\"utf8\") as infile:\n",
    "            file_text= preprocessText(infile.read())\n",
    "            file_topic=''.join(re.findall('[A-Za-z]', file_path.stem))\n",
    "            topic.append(file_topic)\n",
    "            text.append(file_text)\n",
    "    return text, topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b5e805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>آپ ہلیری کے خوف سے بو آسکتے ہیں - آزادی مرکز م...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ٹرمپ کی ریلی میں عین لمحے पल ریان نے سیاسی خود...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over € nInfernoâ € ™ اور زیادہ آبادی کا افسانہ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>رحمت کا جوبلی سال 20 نومبر کو ختم ہوگا۔ فیصلے ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کیا امریکہ کو قومی سلامتی کی ریاست معاف کرنا چ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  آپ ہلیری کے خوف سے بو آسکتے ہیں - آزادی مرکز م...      0\n",
       "1  ٹرمپ کی ریلی میں عین لمحے पल ریان نے سیاسی خود...      0\n",
       "2  Over € nInfernoâ € ™ اور زیادہ آبادی کا افسانہ...      0\n",
       "3  رحمت کا جوبلی سال 20 نومبر کو ختم ہوگا۔ فیصلے ...      0\n",
       "4  کیا امریکہ کو قومی سلامتی کی ریاست معاف کرنا چ...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert both the datasets to dataframes for easy processing\n",
    "\n",
    "# UFN Dataset\n",
    "real = [0] * len(UFN_real_news)\n",
    "fake = [1] * len(UFN_fake_news)\n",
    "\n",
    "d = {'text': UFN_real_news, 'label':  real }\n",
    "df1 = pd.DataFrame(data=d)\n",
    "\n",
    "d = {'text': UFN_fake_news, 'label': fake}\n",
    "df2 = pd.DataFrame(data=d)\n",
    "\n",
    "UFN_df = pd.concat([df1, df2])\n",
    "\n",
    "UFN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a070e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_text_no_punc(s):\n",
    "    string_w = s.translate(str.maketrans('','',string.punctuation)) \n",
    "    return len(string_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e64282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>label</th>\n",
       "      <th>lengh_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>نئی دہلی 0 ڈسمبر(ایجنسی) عالمی بازار کے مثبت س...</td>\n",
       "      <td>bus</td>\n",
       "      <td>1</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿\\nآنجہانی برطانوی رائٹر  کے Jodi Picoltناول ...</td>\n",
       "      <td>sbz</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>شیئر کریں:\\n\\nآنجہانی برطانوی رائٹرP. L. Trav...</td>\n",
       "      <td>sbz</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿\\nلوکا گواڈنینو کی پروڈکشن میں بننے والی فلم ...</td>\n",
       "      <td>sbz</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nنئی دہلی 0 ڈسمبر(ایجنسی) عالمی منڈی اور شادی...</td>\n",
       "      <td>bus</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>لاہور: سرفراز احمد بھی مفت کے ٹکٹ مانگنے والوں...</td>\n",
       "      <td>sp</td>\n",
       "      <td>1</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>آئی سی سی کا بڑا اعلان\\nڈھاکہ 0 دسمبر (سیاست ڈ...</td>\n",
       "      <td>sp</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ممبئی(شوبزڈ یسک) بالی وڈ کے معروف اداکار دھرمن...</td>\n",
       "      <td>sbz</td>\n",
       "      <td>1</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>مصر 0 دسمبر(ایجنسی) ایک اداکارہ کے مبینہ طور س...</td>\n",
       "      <td>sbz</td>\n",
       "      <td>1</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nمصر 0 دسمبر(ایجنسی) ایک اداکارہ کے بوائے فری...</td>\n",
       "      <td>sbz</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text topic  label  lengh_text\n",
       "0  نئی دہلی 0 ڈسمبر(ایجنسی) عالمی بازار کے مثبت س...   bus      1         308\n",
       "1  ﻿\\nآنجہانی برطانوی رائٹر  کے Jodi Picoltناول ...   sbz      0         313\n",
       "2  شیئر کریں:\\n\\nآنجہانی برطانوی رائٹرP. L. Trav...   sbz      1         326\n",
       "3  ﻿\\nلوکا گواڈنینو کی پروڈکشن میں بننے والی فلم ...   sbz      0         332\n",
       "4  \\nنئی دہلی 0 ڈسمبر(ایجنسی) عالمی منڈی اور شادی...   bus      0         334\n",
       "5  لاہور: سرفراز احمد بھی مفت کے ٹکٹ مانگنے والوں...    sp      1         338\n",
       "6  آئی سی سی کا بڑا اعلان\\nڈھاکہ 0 دسمبر (سیاست ڈ...    sp      0         363\n",
       "7  ممبئی(شوبزڈ یسک) بالی وڈ کے معروف اداکار دھرمن...   sbz      1         372\n",
       "8  مصر 0 دسمبر(ایجنسی) ایک اداکارہ کے مبینہ طور س...   sbz      1         380\n",
       "9  \\nمصر 0 دسمبر(ایجنسی) ایک اداکارہ کے بوائے فری...   sbz      0         382"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BET Dataset\n",
    "train_real_news, train_real_news_topics = read_txt_files(sorted(Path('Corpus/Train/Real/').glob('*.txt')))\n",
    "train_fake_news, train_fake_news_topics = read_txt_files(sorted(Path('Corpus/Train/Fake/').glob('*.txt')))\n",
    "\n",
    "real = [1] * len(train_real_news_topics)\n",
    "fake = [0] * len(train_fake_news_topics)\n",
    "\n",
    "d = {'text': train_real_news, 'topic': train_real_news_topics,'label':  real }\n",
    "df1 = pd.DataFrame(data=d)\n",
    "\n",
    "d = {'text': train_fake_news, 'topic': train_fake_news_topics,'label': fake}\n",
    "df2 = pd.DataFrame(data=d)\n",
    "\n",
    "Train_data = pd.concat([df1,df2])\n",
    "\n",
    "#load test data\n",
    "real_news, real_news_topics = read_txt_files(sorted(Path('Corpus/Test/Real/').glob('*.txt')))\n",
    "fake_news, fake_news_topics = read_txt_files(sorted(Path('Corpus/Test/Fake/').glob('*.txt')))\n",
    "\n",
    "real = [1] * len(real_news_topics)\n",
    "fake = [0] * len(fake_news_topics)\n",
    "\n",
    "d = {'text': real_news, 'topic': real_news_topics,'label': real}\n",
    "df1 = pd.DataFrame(data=d)\n",
    "d = {'text': fake_news, 'topic': fake_news_topics,'label': fake}\n",
    "df2 = pd.DataFrame(data=d)\n",
    "\n",
    "Test_data = pd.concat([df1,df2])\n",
    "df = pd.concat([Train_data,Test_data])\n",
    "\n",
    "df['lengh_text'] = df['text'].apply(len_text_no_punc)\n",
    "df = df.sort_values(by=['lengh_text'], ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df[df['lengh_text']>=6] # only keep text with len more than 6 because n char\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74628c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lengh_text</th>\n",
       "      <th>bus</th>\n",
       "      <th>hlth</th>\n",
       "      <th>sbz</th>\n",
       "      <th>sp</th>\n",
       "      <th>tch</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>نئی دہلی 0 ڈسمبر(ایجنسی) عالمی بازار کے مثبت س...</td>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿\\nآنجہانی برطانوی رائٹر  کے Jodi Picoltناول ...</td>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>شیئر کریں:\\n\\nآنجہانی برطانوی رائٹرP. L. Trav...</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿\\nلوکا گواڈنینو کی پروڈکشن میں بننے والی فلم ...</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nنئی دہلی 0 ڈسمبر(ایجنسی) عالمی منڈی اور شادی...</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>لاہور: سرفراز احمد بھی مفت کے ٹکٹ مانگنے والوں...</td>\n",
       "      <td>338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>آئی سی سی کا بڑا اعلان\\nڈھاکہ 0 دسمبر (سیاست ڈ...</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ممبئی(شوبزڈ یسک) بالی وڈ کے معروف اداکار دھرمن...</td>\n",
       "      <td>372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>مصر 0 دسمبر(ایجنسی) ایک اداکارہ کے مبینہ طور س...</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nمصر 0 دسمبر(ایجنسی) ایک اداکارہ کے بوائے فری...</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  lengh_text  bus  hlth  \\\n",
       "0  نئی دہلی 0 ڈسمبر(ایجنسی) عالمی بازار کے مثبت س...         308    1     0   \n",
       "1  ﻿\\nآنجہانی برطانوی رائٹر  کے Jodi Picoltناول ...         313    0     0   \n",
       "2  شیئر کریں:\\n\\nآنجہانی برطانوی رائٹرP. L. Trav...         326    0     0   \n",
       "3  ﻿\\nلوکا گواڈنینو کی پروڈکشن میں بننے والی فلم ...         332    0     0   \n",
       "4  \\nنئی دہلی 0 ڈسمبر(ایجنسی) عالمی منڈی اور شادی...         334    1     0   \n",
       "5  لاہور: سرفراز احمد بھی مفت کے ٹکٹ مانگنے والوں...         338    0     0   \n",
       "6  آئی سی سی کا بڑا اعلان\\nڈھاکہ 0 دسمبر (سیاست ڈ...         363    0     0   \n",
       "7  ممبئی(شوبزڈ یسک) بالی وڈ کے معروف اداکار دھرمن...         372    0     0   \n",
       "8  مصر 0 دسمبر(ایجنسی) ایک اداکارہ کے مبینہ طور س...         380    0     0   \n",
       "9  \\nمصر 0 دسمبر(ایجنسی) ایک اداکارہ کے بوائے فری...         382    0     0   \n",
       "\n",
       "   sbz  sp  tch  label  \n",
       "0    0   0    0      1  \n",
       "1    1   0    0      0  \n",
       "2    1   0    0      1  \n",
       "3    1   0    0      0  \n",
       "4    0   0    0      0  \n",
       "5    0   1    0      1  \n",
       "6    0   1    0      0  \n",
       "7    1   0    0      1  \n",
       "8    1   0    0      1  \n",
       "9    1   0    0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['topic'])], axis=1)  \n",
    "classe = df['label']\n",
    "df = df.drop([\"label\",\"topic\"], axis=1)\n",
    "BET_df = pd.concat([df,classe], axis=1)\n",
    "BET_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2467269b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lengh_text</th>\n",
       "      <th>bus</th>\n",
       "      <th>hlth</th>\n",
       "      <th>sbz</th>\n",
       "      <th>sp</th>\n",
       "      <th>tch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>نئی دہلی 0 ڈسمبر(ایجنسی) عالمی بازار کے مثبت س...</td>\n",
       "      <td>-1.057498</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿\\nآنجہانی برطانوی رائٹر  کے Jodi Picoltناول ...</td>\n",
       "      <td>-1.053373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>شیئر کریں:\\n\\nآنجہانی برطانوی رائٹرP. L. Trav...</td>\n",
       "      <td>-1.042645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>﻿\\nلوکا گواڈنینو کی پروڈکشن میں بننے والی فلم ...</td>\n",
       "      <td>-1.037694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nنئی دہلی 0 ڈسمبر(ایجنسی) عالمی منڈی اور شادی...</td>\n",
       "      <td>-1.036044</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>لاہور: سرفراز احمد بھی مفت کے ٹکٹ مانگنے والوں...</td>\n",
       "      <td>-1.032743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>آئی سی سی کا بڑا اعلان\\nڈھاکہ 0 دسمبر (سیاست ڈ...</td>\n",
       "      <td>-1.012113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ممبئی(شوبزڈ یسک) بالی وڈ کے معروف اداکار دھرمن...</td>\n",
       "      <td>-1.004686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>مصر 0 دسمبر(ایجنسی) ایک اداکارہ کے مبینہ طور س...</td>\n",
       "      <td>-0.998085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nمصر 0 دسمبر(ایجنسی) ایک اداکارہ کے بوائے فری...</td>\n",
       "      <td>-0.996435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  lengh_text  bus  hlth  \\\n",
       "0  نئی دہلی 0 ڈسمبر(ایجنسی) عالمی بازار کے مثبت س...   -1.057498    1     0   \n",
       "1  ﻿\\nآنجہانی برطانوی رائٹر  کے Jodi Picoltناول ...   -1.053373    0     0   \n",
       "2  شیئر کریں:\\n\\nآنجہانی برطانوی رائٹرP. L. Trav...   -1.042645    0     0   \n",
       "3  ﻿\\nلوکا گواڈنینو کی پروڈکشن میں بننے والی فلم ...   -1.037694    0     0   \n",
       "4  \\nنئی دہلی 0 ڈسمبر(ایجنسی) عالمی منڈی اور شادی...   -1.036044    1     0   \n",
       "5  لاہور: سرفراز احمد بھی مفت کے ٹکٹ مانگنے والوں...   -1.032743    0     0   \n",
       "6  آئی سی سی کا بڑا اعلان\\nڈھاکہ 0 دسمبر (سیاست ڈ...   -1.012113    0     0   \n",
       "7  ممبئی(شوبزڈ یسک) بالی وڈ کے معروف اداکار دھرمن...   -1.004686    0     0   \n",
       "8  مصر 0 دسمبر(ایجنسی) ایک اداکارہ کے مبینہ طور س...   -0.998085    0     0   \n",
       "9  \\nمصر 0 دسمبر(ایجنسی) ایک اداکارہ کے بوائے فری...   -0.996435    0     0   \n",
       "\n",
       "   sbz  sp  tch  \n",
       "0    0   0    0  \n",
       "1    1   0    0  \n",
       "2    1   0    0  \n",
       "3    1   0    0  \n",
       "4    0   0    0  \n",
       "5    0   1    0  \n",
       "6    0   1    0  \n",
       "7    1   0    0  \n",
       "8    1   0    0  \n",
       "9    1   0    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[['lengh_text']].values.astype(float)\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "df['lengh_text'] = min_max_scaler.fit_transform(x)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97034b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1032\n",
       " 1     968\n",
       " Name: label, dtype: int64,\n",
       " 1    500\n",
       " 0    400\n",
       " Name: label, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UFN_df.label.value_counts(), BET_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27285c33",
   "metadata": {},
   "source": [
    "### 3. Split the datasets in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d1294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainU, X_testU, y_trainU, y_testU = train_test_split(\n",
    "    UFN_df.loc[:, UFN_df.columns != 'label'], \n",
    "    UFN_df.loc[:, UFN_df.columns == 'label'], \n",
    "    test_size = 0.35, \n",
    "    random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4675db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainB, X_testB, y_trainB, y_testB = train_test_split(\n",
    "    BET_df.loc[:, BET_df.columns != 'label'], \n",
    "    BET_df.loc[:, BET_df.columns == 'label'], \n",
    "    test_size = 0.35, \n",
    "    random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab883e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((585, 7), (315, 7), (585, 1), (315, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainB.shape, X_testB.shape, y_trainB.shape, y_testB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae44b16",
   "metadata": {},
   "source": [
    "### 4. Define the Feature Extractor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9682f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor: \n",
    "    \"\"\"Feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self, cnvalues, wnvalues, fnvalues): \n",
    "        self.cnvalues = cnvalues\n",
    "        self.wnvalues = wnvalues\n",
    "        self.fnvalues = fnvalues\n",
    "        self.vectorizer = CountVectorizer(lowercase=False, min_df=2, tokenizer=lambda x: x.split('&%$')) #--> we can change this\n",
    "    \n",
    "    def process_texts(self,texts,cn,wn,fn):\n",
    "        occurrences=defaultdict(int)\n",
    "        featuresList=[]\n",
    "        featuresDict=Counter()\n",
    "        for (text) in texts:\n",
    "            features=self.extract_features(text,cn,wn,fn)\n",
    "            featuresDict.update(features)\n",
    "            featuresList.append('&%$'.join(features))\n",
    "        return featuresList, featuresDict\n",
    "       \n",
    "    def fit_extract(self, train_texts):\n",
    "        train_features, dicOfFeatures = self.process_texts(train_texts, self.cnvalues, self.wnvalues, self.fnvalues)\n",
    "        train_data = self.vectorizer.fit_transform(train_features)\n",
    "        train_data = train_data.astype(float)\n",
    "        return train_data, dicOfFeatures\n",
    "    \n",
    "    def extract(self, test_texts): \n",
    "        test_features, dicOfFeaturesTest = self.process_texts(test_texts, self.cnvalues, self.wnvalues, self.fnvalues)\n",
    "        test_data = self.vectorizer.transform(test_features)\n",
    "        test_data = test_data.astype(float)\n",
    "        return test_data, dicOfFeaturesTest \n",
    "    \n",
    "    def wordNgrams(self,text, n):\n",
    "        ngrams = []\n",
    "        text = [word for word in text.split() if word not in string.punctuation]\n",
    "        ngrams = [' '.join(text[i:i+n])+'' for i in range(len(text)-n+1)]\n",
    "        return ngrams\n",
    "    \n",
    "    def charNgrams(self,text, n):\n",
    "        ngrams = []\n",
    "        ngrams = [text[i:i+n] for i in range(len(text)-n+1)]\n",
    "        return ngrams\n",
    "    #Extracts function words n-grams with a pre-loaded dictionary\n",
    "    def funcNgrams(self,text, n):\n",
    "        stop_words = self.load_diccionario('stop_words.txt')\n",
    "        patt=r'\\b(' + ('|'.join(re.escape(key) for key in stop_words)).lstrip('|') + r')\\b'\n",
    "        pattern = re.compile(patt)\n",
    "        text = re.sub(r\"(\\n+|\\r+|(\\r\\n)+)\", \" \", text)\n",
    "        text = re.sub(r\" +\", \" \", text)\n",
    "        text = re.sub(r\"’\", \"'\", text)\n",
    "        text = re.sub(r\"[\" + string.punctuation + \"]*\", \"\", text)\n",
    "        terms = pattern.findall(text)\n",
    "        n_grams=[('_'.join(terms[i:i+n])) + \"_fwn\" for i in range(len(terms)-n+1)]\n",
    "        return n_grams\n",
    "    \n",
    "    def extract_features(self,text,cn,wn,fn):\n",
    "        text = text.lower()\n",
    "        features = []\n",
    "        if(cn>0):\n",
    "            features.extend(self.charNgrams(text,cn))\n",
    "        if(wn>0):\n",
    "            features.extend(self.wordNgrams(text,wn))\n",
    "        if(fn>0):\n",
    "            features.extend(self.funcNgrams(text,fn))\n",
    "        return features\n",
    "    \n",
    "    # Extracts all features in a set of 'texts' and return as a string separated with the simbol '&%$'\n",
    "\n",
    "    def load_diccionario(self,ruta):\n",
    "        terms = set()#Dictionary of slangs\n",
    "        try:\n",
    "            tmp = open(ruta, \"r\", encoding='utf8')     \n",
    "            while True :\n",
    "                linea = tmp.readline()                                                                                   \n",
    "                #linea = to_unicode(linea) \n",
    "                if (not linea) or (linea == \"\"):                                                                               \n",
    "                    break;                                                                                                      \n",
    "                linea = linea.rstrip()\n",
    "                terms.add(linea.lower())\n",
    "            return (terms)\n",
    "        except IOError as e:\n",
    "            print (\"Error: \"+ruta+\" I/O error({0}): {1}\".format(e.errno, e.strerror))\n",
    "            exit(1)\n",
    "            \n",
    "    def apply_frequency_threshold(self,feature_mx, N=5):\n",
    "        values=np.array(feature_mx.sum(axis=0)).ravel()\n",
    "        thresholdMask=(values >= N)*1\n",
    "        indices_zero = list(np.nonzero(thresholdMask == 0)[0])\n",
    "        all_cols = np.arange(feature_mx.shape[1])\n",
    "        cols_to_keep = np.where(np.logical_not(np.in1d(all_cols, indices_zero)))[0]\n",
    "        return cols_to_keep "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8beea94",
   "metadata": {},
   "source": [
    "### 5. Define weighting schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "277c17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighting_scheme(feature_weight_name): \n",
    "    \n",
    "    if feature_weight_name == 'binary':\n",
    "        #print (\"feature_weight = binary\")\n",
    "        return preprocessing.Binarizer()\n",
    "        \n",
    "    elif feature_weight_name == 'tfidf':\n",
    "        #print (\"feature_weight = tfidf\")\n",
    "        return TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9fe715",
   "metadata": {},
   "source": [
    "### 6. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "700f5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_extractor = FeatureExtractor(2, 1, 2)  # char-ngrams, word-ngrams, functional-ngrams\n",
    "\n",
    "def get_features(df_train, df_test):\n",
    "    train_feature, _ = feat_extractor.fit_extract(df_train['text'])\n",
    "    test_feature, _ = feat_extractor.extract(df_test['text']) \n",
    "\n",
    "    #applying the frequency threshold\n",
    "    cols_to_keep = feat_extractor.apply_frequency_threshold(train_feature)\n",
    "    thresholded_train_f = train_feature[:, cols_to_keep]\n",
    "    thresholded_test_f = test_feature[:, cols_to_keep]\n",
    "    \n",
    "    return thresholded_train_f, thresholded_test_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a168379",
   "metadata": {},
   "source": [
    "### 7. Results for Binary features and feature selection on them for UFN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8618aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X = get_features(X_trainU, X_testU)\n",
    "train_y, test_y = y_trainU.values.reshape(-1), y_testU.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6c12466",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = get_weighting_scheme('binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0dd1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_train_X = transformer.fit_transform(train_X)\n",
    "weighted_test_X = transformer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb4c7e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=300, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(learning_rate=0.1, n_estimators=300, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.1, n_estimators=300, random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfAB = AdaBoostClassifier(n_estimators=300, learning_rate=.1,  random_state=0)\n",
    "clfAB.fit(weighted_train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d35f172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.89\n"
     ]
    }
   ],
   "source": [
    "y_hat = clfAB.predict(weighted_test_X)\n",
    "print('Acc:', accuracy_score(test_y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "708ee990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1300, 22121), (1300,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bfe635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  2000\n"
     ]
    }
   ],
   "source": [
    "from feature_selection import FeatureSelection\n",
    "\n",
    "fs = FeatureSelection()\n",
    "\n",
    "fs_metrics = [fs.acc2, fs.ndm, fs.bns, fs.odds_ratio, fs.gini, fs.dfs, fs.IG, fs.ChiSquare ]\n",
    "fs_metric_names = [x.__name__ for x in fs_metrics]\n",
    "\n",
    "results_df = pd.DataFrame(columns=fs_metric_names) \n",
    "\n",
    "no_of_terms = [100, 200, 300, 400, 500, 1000, 1500, 2000]\n",
    "\n",
    "for k_val in no_of_terms:\n",
    "    row = []\n",
    "    for metric in fs_metrics:\n",
    "        selector = SelectKBest(score_func=partial(metric), k=k_val)\n",
    "        subset_train_X = selector.fit_transform(weighted_train_X, train_y)\n",
    "        subset_test_X = selector.transform(weighted_test_X)\n",
    "        clfAB = AdaBoostClassifier(n_estimators=300, learning_rate=.1,  random_state=0)\n",
    "        clfAB.fit(subset_train_X, train_y)\n",
    "        y_hat = clfAB.predict(subset_test_X)\n",
    "        row.append(accuracy_score(test_y, y_hat))\n",
    "    \n",
    "    results_df.loc[len(results_df),] = row\n",
    "    print('Done for features: ', k_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32957b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc2</th>\n",
       "      <th>ndm</th>\n",
       "      <th>bns</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>gini</th>\n",
       "      <th>dfs</th>\n",
       "      <th>IG</th>\n",
       "      <th>ChiSquare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.768571</td>\n",
       "      <td>0.631429</td>\n",
       "      <td>0.547143</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0.835714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.652857</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.865714</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.845714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.831429</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.715714</td>\n",
       "      <td>0.865714</td>\n",
       "      <td>0.865714</td>\n",
       "      <td>0.864286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.802857</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.665714</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.865714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.861429</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.668571</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.871429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.877143</td>\n",
       "      <td>0.854286</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.725714</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.887143</td>\n",
       "      <td>0.884286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.741429</td>\n",
       "      <td>0.865714</td>\n",
       "      <td>0.888571</td>\n",
       "      <td>0.881429</td>\n",
       "      <td>0.888571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.895714</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.875714</td>\n",
       "      <td>0.751429</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.882857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc2       ndm       bns odds_ratio      gini       dfs        IG  \\\n",
       "0  0.805714  0.778571  0.768571   0.631429  0.547143  0.851429  0.837143   \n",
       "1  0.842857  0.778571  0.802857   0.652857      0.63  0.865714      0.86   \n",
       "2  0.854286       0.8  0.831429   0.644286  0.715714  0.865714  0.865714   \n",
       "3  0.845714  0.802857  0.835714   0.665714  0.757143  0.862857  0.864286   \n",
       "4  0.861429  0.812857  0.851429   0.668571  0.807143      0.88  0.868571   \n",
       "5  0.877143  0.854286  0.858571   0.725714      0.84  0.888571  0.887143   \n",
       "6  0.888571  0.858571      0.87   0.741429  0.865714  0.888571  0.881429   \n",
       "7  0.895714  0.851429  0.875714   0.751429      0.88  0.878571  0.882857   \n",
       "\n",
       "  ChiSquare  \n",
       "0  0.835714  \n",
       "1  0.845714  \n",
       "2  0.864286  \n",
       "3  0.865714  \n",
       "4  0.871429  \n",
       "5  0.884286  \n",
       "6  0.888571  \n",
       "7  0.882857  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3101bb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc2</th>\n",
       "      <th>ndm</th>\n",
       "      <th>bns</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>gini</th>\n",
       "      <th>dfs</th>\n",
       "      <th>IG</th>\n",
       "      <th>ChiSquare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.768571</td>\n",
       "      <td>0.631429</td>\n",
       "      <td>0.547143</td>\n",
       "      <td>0.865714</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0.835714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc2       ndm       bns  odds_ratio      gini       dfs  \\\n",
       "count   8.000000  8.000000  8.000000    8.000000  8.000000  8.000000   \n",
       "unique  8.000000  7.000000  8.000000    8.000000  8.000000  6.000000   \n",
       "top     0.805714  0.778571  0.768571    0.631429  0.547143  0.865714   \n",
       "freq    1.000000  2.000000  1.000000    1.000000  1.000000  2.000000   \n",
       "\n",
       "              IG  ChiSquare  \n",
       "count   8.000000   8.000000  \n",
       "unique  8.000000   8.000000  \n",
       "top     0.837143   0.835714  \n",
       "freq    1.000000   1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8507e2d",
   "metadata": {},
   "source": [
    "### 8. Results for Binary Features and Feature Selection for BET Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d2debad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X = get_features(X_trainB, X_testB)\n",
    "train_y, test_y = y_trainB.values.reshape(-1), y_testB.values.reshape(-1)\n",
    "train_X.shape\n",
    "transformer = get_weighting_scheme('binary')\n",
    "\n",
    "weighted_train_X = transformer.fit_transform(train_X)\n",
    "weighted_test_X = transformer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca648033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# perform classification\n",
    "clfAB = AdaBoostClassifier(n_estimators=300, learning_rate=.1,  random_state=0)\n",
    "clfAB.fit(weighted_train_X, train_y)\n",
    "\n",
    "y_hat = clfAB.predict(weighted_test_X)\n",
    "print('Acc:', accuracy_score(test_y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fbc28cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\feature_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  tn = self.tn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:116: RuntimeWarning: invalid value encountered in divide\n",
      "  fn = self.fn / (self.tn + self.fn)\n",
      "C:\\Users\\MuhammadWasim\\feature_selection.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  return (self.tp * self.tn - self.fn * self.fp)**2 / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for features:  2000\n"
     ]
    }
   ],
   "source": [
    "from feature_selection import FeatureSelection\n",
    "\n",
    "fs = FeatureSelection()\n",
    "\n",
    "fs_metrics = [fs.acc2, fs.ndm, fs.bns, fs.odds_ratio, fs.gini, fs.dfs, fs.IG, fs.ChiSquare ]\n",
    "fs_metric_names = [x.__name__ for x in fs_metrics]\n",
    "\n",
    "results_df1 = pd.DataFrame(columns=fs_metric_names)\n",
    "\n",
    "no_of_terms = [100, 200, 300, 400, 500, 1000, 1500, 2000]\n",
    "\n",
    "for k_val in no_of_terms:\n",
    "    row = []\n",
    "    for metric in fs_metrics:\n",
    "        selector = SelectKBest(score_func=partial(metric), k=k_val)\n",
    "        subset_train_X = selector.fit_transform(weighted_train_X, train_y)\n",
    "        subset_test_X = selector.transform(weighted_test_X)\n",
    "        clfAB = AdaBoostClassifier(n_estimators=300, learning_rate=.1,  random_state=0)\n",
    "        clfAB.fit(subset_train_X, train_y)\n",
    "        y_hat = clfAB.predict(subset_test_X)\n",
    "        row.append(accuracy_score(test_y, y_hat))\n",
    "    \n",
    "    results_df1.loc[len(results_df1),] = row\n",
    "    print('Done for features: ', k_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "367382cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc2</th>\n",
       "      <th>ndm</th>\n",
       "      <th>bns</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>gini</th>\n",
       "      <th>dfs</th>\n",
       "      <th>IG</th>\n",
       "      <th>ChiSquare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.892063</td>\n",
       "      <td>0.692063</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.87619</td>\n",
       "      <td>0.879365</td>\n",
       "      <td>0.87619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.803175</td>\n",
       "      <td>0.860317</td>\n",
       "      <td>0.84127</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88254</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.812698</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.850794</td>\n",
       "      <td>0.850794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.831746</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.784127</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.831746</td>\n",
       "      <td>0.863492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.88254</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.765079</td>\n",
       "      <td>0.787302</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.873016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.87619</td>\n",
       "      <td>0.84127</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.869841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.860317</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.863492</td>\n",
       "      <td>0.84127</td>\n",
       "      <td>0.84127</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.850794</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.869841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc2       ndm       bns odds_ratio      gini       dfs        IG  \\\n",
       "0  0.892063  0.692063  0.847619   0.742857  0.507937   0.87619  0.879365   \n",
       "1  0.873016  0.809524  0.777778        0.8  0.803175  0.860317   0.84127   \n",
       "2   0.88254  0.819048  0.755556   0.761905  0.812698  0.853968  0.850794   \n",
       "3  0.873016  0.831746  0.730159   0.784127  0.838095  0.866667  0.831746   \n",
       "4   0.88254  0.847619  0.765079   0.787302  0.863492  0.866667  0.869841   \n",
       "5   0.87619   0.84127  0.853968   0.822222  0.863492  0.869841  0.869841   \n",
       "6  0.860317  0.847619  0.853968   0.834921  0.866667  0.847619  0.873016   \n",
       "7  0.863492   0.84127   0.84127   0.838095  0.850794  0.853968  0.869841   \n",
       "\n",
       "  ChiSquare  \n",
       "0   0.87619  \n",
       "1  0.847619  \n",
       "2  0.850794  \n",
       "3  0.863492  \n",
       "4  0.873016  \n",
       "5  0.869841  \n",
       "6  0.857143  \n",
       "7  0.869841  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af5bc6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc2</th>\n",
       "      <th>ndm</th>\n",
       "      <th>bns</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>gini</th>\n",
       "      <th>dfs</th>\n",
       "      <th>IG</th>\n",
       "      <th>ChiSquare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>0.853968</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.869841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc2       ndm       bns  odds_ratio      gini       dfs  \\\n",
       "count   8.000000  8.000000  8.000000    8.000000  8.000000  8.000000   \n",
       "unique  6.000000  6.000000  7.000000    8.000000  7.000000  6.000000   \n",
       "top     0.873016  0.847619  0.853968    0.742857  0.863492  0.853968   \n",
       "freq    2.000000  2.000000  2.000000    1.000000  2.000000  2.000000   \n",
       "\n",
       "              IG  ChiSquare  \n",
       "count   8.000000   8.000000  \n",
       "unique  6.000000   7.000000  \n",
       "top     0.869841   0.869841  \n",
       "freq    3.000000   2.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e4377",
   "metadata": {},
   "source": [
    "### 9. Results on the Proposed Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0351bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_size_score(X, y):\n",
    "    \n",
    "        classes = list(np.unique(y))\n",
    "\n",
    "        positive = X[y==classes[0]].copy()\n",
    "        negative = X[y==classes[1]].copy()\n",
    "\n",
    "        positive = positive.toarray()\n",
    "        negative = negative.toarray()\n",
    "        \n",
    "        pos_mean = positive.mean(axis=0)\n",
    "        neg_mean = negative.mean(axis=0)\n",
    "        \n",
    "        pos_std = positive.std(axis=0)\n",
    "        neg_std = negative.std(axis=0)\n",
    "\n",
    "        es_val = np.abs(pos_mean - neg_mean) / (pos_std + neg_std)\n",
    "        \n",
    "        return es_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16979ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Urdu Fake News Dataset\n",
    "train_X, test_X = get_features(X_trainU, X_testU)\n",
    "train_y, test_y = y_trainU.values.reshape(-1), y_testU.values.reshape(-1)\n",
    "transformer = get_weighting_scheme('tfidf')\n",
    "weighted_train_X = transformer.fit_transform(train_X)\n",
    "weighted_test_X = transformer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "131674fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8928571428571429\n"
     ]
    }
   ],
   "source": [
    "# perform classification\n",
    "clfAB = AdaBoostClassifier(n_estimators=300, learning_rate=.1,  random_state=0)\n",
    "clfAB.fit(weighted_train_X, train_y)\n",
    "\n",
    "y_hat = clfAB.predict(weighted_test_X)\n",
    "print('Acc:', accuracy_score(test_y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34837561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Val: 100 Acc: 0.8785714285714286\n",
      "K Val: 200 Acc: 0.8942857142857142\n",
      "K Val: 300 Acc: 0.9014285714285715\n",
      "K Val: 400 Acc: 0.8857142857142857\n",
      "K Val: 500 Acc: 0.8928571428571429\n",
      "K Val: 1000 Acc: 0.8914285714285715\n",
      "K Val: 1500 Acc: 0.8885714285714286\n",
      "K Val: 2000 Acc: 0.8885714285714286\n"
     ]
    }
   ],
   "source": [
    "# perform classification\n",
    "\n",
    "no_of_terms = [100, 200, 300, 400, 500, 1000, 1500, 2000]\n",
    "\n",
    "for k_val in no_of_terms:\n",
    "    selector = SelectKBest(score_func=partial(effect_size_score), k=k_val)\n",
    "    subset_train_X = selector.fit_transform(weighted_train_X, train_y)\n",
    "    subset_test_X = selector.transform(weighted_test_X)\n",
    "\n",
    "    clfAB = AdaBoostClassifier(n_estimators=300, learning_rate=.1,  random_state=0)\n",
    "    clfAB.fit(subset_train_X, train_y)\n",
    "\n",
    "    y_hat = clfAB.predict(subset_test_X)\n",
    "    print('K Val:', k_val, 'Acc:', accuracy_score(test_y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dab67a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MuhammadWasim\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Bend the Truth Dataset\n",
    "train_X, test_X = get_features(X_trainB, X_testB)\n",
    "train_y, test_y = y_trainB.values.reshape(-1), y_testB.values.reshape(-1)\n",
    "transformer = get_weighting_scheme('tfidf')\n",
    "weighted_train_X = transformer.fit_transform(train_X)\n",
    "weighted_test_X = transformer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecfa4963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.8634920634920635\n"
     ]
    }
   ],
   "source": [
    "# perform classification\n",
    "clfAB = AdaBoostClassifier(n_estimators=300, learning_rate=.1,  random_state=0)\n",
    "clfAB.fit(weighted_train_X, train_y)\n",
    "\n",
    "y_hat = clfAB.predict(weighted_test_X)\n",
    "print('Acc:', accuracy_score(test_y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88ec527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Val: 100 Acc: 0.873015873015873\n",
      "K Val: 200 Acc: 0.8793650793650793\n",
      "K Val: 300 Acc: 0.8603174603174604\n",
      "K Val: 400 Acc: 0.8634920634920635\n",
      "K Val: 500 Acc: 0.8698412698412699\n",
      "K Val: 1000 Acc: 0.8507936507936508\n",
      "K Val: 1500 Acc: 0.8539682539682539\n",
      "K Val: 2000 Acc: 0.8507936507936508\n",
      "K Val: 2500 Acc: 0.8634920634920635\n",
      "K Val: 3000 Acc: 0.8698412698412699\n"
     ]
    }
   ],
   "source": [
    "no_of_terms = [100, 200, 300, 400, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "\n",
    "for k_val in no_of_terms:\n",
    "    selector = SelectKBest(score_func=partial(effect_size_score), k=k_val)\n",
    "    subset_train_X = selector.fit_transform(weighted_train_X, train_y)\n",
    "    subset_test_X = selector.transform(weighted_test_X)\n",
    "\n",
    "    clfAB = AdaBoostClassifier(n_estimators=200, learning_rate=.1,  random_state=0)\n",
    "    clfAB.fit(subset_train_X, train_y)\n",
    "\n",
    "    y_hat = clfAB.predict(subset_test_X)\n",
    "    print('K Val:', k_val, 'Acc:', accuracy_score(test_y, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb74134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
